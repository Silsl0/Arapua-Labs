{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Silsl0/Arapua-Labs/blob/main/ArapuaLabs_AutoDetect_WebMap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "badge"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "id": "badge"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# Arapuá Labs — Results & Web Map (Folium)\n",
        "This notebook reads exported GeoJSON files (wet/dry lagoon polygons and offset vectors), computes KPIs, and builds an interactive Folium map. It includes:\n",
        "- Google Drive auto-discovery of files and path normalization\n",
        "- Robust CRS handling (UTM for areas and vector construction)\n",
        "- Safe use of `union_all()`/`unary_union`\n",
        "- Vector line creation from `(dx_m, dy_m)` points in meters\n"
      ],
      "id": "intro"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24249f7a-5ea3-4408-c9db-efb12ee86ab2"
      },
      "source": [
        "%pip install -q folium geopandas shapely pyproj mapclassify"
      ],
      "id": "pip",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/882.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m880.6/882.2 kB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m882.2/882.2 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "params_mount",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c70927e-fd4d-44bc-a827-86ded1597f4b"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "DRIVE_ROOT = '/content/drive/MyDrive'  # Colab default\n",
        "TARGET_DIR = os.path.join(DRIVE_ROOT, 'ArapuaLabs_GEE_Exports')\n",
        "os.makedirs(TARGET_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.join(TARGET_DIR, 'offset_outputs'), exist_ok=True)\n",
        "\n",
        "WET_DATE = '2024-05-15'\n",
        "DRY_DATE = '2024-09-15'\n"
      ],
      "id": "params_mount",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "autodiscovery",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b588e5-d873-4e30-9132-75520c4d0511"
      },
      "source": [
        "import glob, shutil, json, os\n",
        "\n",
        "def find_first(patterns, root):\n",
        "    for pat in patterns:\n",
        "        hits = glob.glob(os.path.join(root, '**', pat), recursive=True)\n",
        "        if hits:\n",
        "            hits = sorted(hits, key=len)\n",
        "            return hits[0], hits\n",
        "    return None, []\n",
        "\n",
        "wet_path, _ = find_first(['Polygons_Lagoons_Wet.geojson', '*Lagoons*Wet*.geojson'], DRIVE_ROOT)\n",
        "dry_path, _ = find_first(['Polygons_Lagoons_Dry.geojson', '*Lagoons*Dry*.geojson'], DRIVE_ROOT)\n",
        "lines_path, _ = find_first(['offset_vectors_lines.geojson', '*offset*lines*.geojson'], DRIVE_ROOT)\n",
        "points_path, _ = find_first(['offset_vectors.geojson', '*offset*vectors*.geojson'], DRIVE_ROOT)\n",
        "\n",
        "print('Auto-discovery:')\n",
        "print('  wet   :', wet_path)\n",
        "print('  dry   :', dry_path)\n",
        "print('  lines :', lines_path)\n",
        "print('  points:', points_path)\n",
        "\n",
        "def safe_copy(src, dst_dir):\n",
        "    if src and os.path.exists(src):\n",
        "        dst = os.path.join(dst_dir, os.path.basename(src))\n",
        "        if os.path.abspath(src) != os.path.abspath(dst):\n",
        "            shutil.copy2(src, dst)\n",
        "        return dst\n",
        "    return None\n",
        "\n",
        "if not wet_path or not dry_path:\n",
        "    raise FileNotFoundError('Wet/Dry lagoon polygons not found in Drive. Ensure they exist and re-run.')\n",
        "\n",
        "WET_GJ   = safe_copy(wet_path, TARGET_DIR)\n",
        "DRY_GJ   = safe_copy(dry_path, TARGET_DIR)\n",
        "LINES_GJ = safe_copy(lines_path, os.path.join(TARGET_DIR, 'offset_outputs')) if lines_path else None\n",
        "POINTS_GJ= safe_copy(points_path, os.path.join(TARGET_DIR, 'offset_outputs')) if points_path else None\n",
        "\n",
        "OUT_HTML = os.path.join(TARGET_DIR, 'map_results.html')\n",
        "OUT_JSON = os.path.join(TARGET_DIR, 'summary_results.json')\n",
        "\n",
        "autopaths = {\n",
        "    'DRIVE_DIR': TARGET_DIR,\n",
        "    'WET_GJ': WET_GJ,\n",
        "    'DRY_GJ': DRY_GJ,\n",
        "    'LINES_GJ': LINES_GJ,\n",
        "    'POINTS_GJ': POINTS_GJ,\n",
        "    'OUT_HTML': OUT_HTML,\n",
        "    'OUT_JSON': OUT_JSON,\n",
        "}\n",
        "with open(os.path.join(TARGET_DIR, '_autopaths.json'), 'w') as f:\n",
        "    json.dump(autopaths, f, indent=2)\n",
        "\n",
        "print('\\nNormalized paths:')\n",
        "for k, v in autopaths.items():\n",
        "    print(f'{k:10s} = {v}')\n"
      ],
      "id": "autodiscovery",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auto-discovery:\n",
            "  wet   : /content/drive/MyDrive/SertAI_GEE_Exports/Polygons_Lagoons_Wet.geojson\n",
            "  dry   : /content/drive/MyDrive/SertAI_GEE_Exports/Polygons_Lagoons_Dry.geojson\n",
            "  lines : None\n",
            "  points: /content/drive/MyDrive/SertAI_GEE_Exports/offset_outputs/offset_vectors.geojson\n",
            "\n",
            "Normalized paths:\n",
            "DRIVE_DIR  = /content/drive/MyDrive/ArapuaLabs_GEE_Exports\n",
            "WET_GJ     = /content/drive/MyDrive/ArapuaLabs_GEE_Exports/Polygons_Lagoons_Wet.geojson\n",
            "DRY_GJ     = /content/drive/MyDrive/ArapuaLabs_GEE_Exports/Polygons_Lagoons_Dry.geojson\n",
            "LINES_GJ   = None\n",
            "POINTS_GJ  = /content/drive/MyDrive/ArapuaLabs_GEE_Exports/offset_outputs/offset_vectors.geojson\n",
            "OUT_HTML   = /content/drive/MyDrive/ArapuaLabs_GEE_Exports/map_results.html\n",
            "OUT_JSON   = /content/drive/MyDrive/ArapuaLabs_GEE_Exports/summary_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpis_helpers"
      },
      "source": [
        "import os, json\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "from shapely.geometry import LineString, Point\n",
        "\n",
        "def safe_exists(p):\n",
        "    return isinstance(p, (str, os.PathLike)) and len(str(p)) > 0 and os.path.exists(p)\n",
        "\n",
        "def union_geom_wgs84(gdf):\n",
        "    g = gdf.to_crs(4326).geometry\n",
        "    if hasattr(g, 'union_all'):\n",
        "        return g.union_all()\n",
        "    return g.unary_union\n",
        "\n",
        "def auto_utm_crs(gdf):\n",
        "    u = union_geom_wgs84(gdf)\n",
        "    c = u.centroid\n",
        "    lon, lat = float(c.x), float(c.y)\n",
        "    zone = int((lon + 180)//6) + 1\n",
        "    south = '+south' if lat < 0 else ''\n",
        "    return f'+proj=utm +zone={zone} {south} +datum=WGS84 +units=m +no_defs'\n",
        "\n",
        "def get_center_latlon(gdf):\n",
        "    u = union_geom_wgs84(gdf)\n",
        "    c = u.centroid\n",
        "    return float(c.y), float(c.x)\n"
      ],
      "id": "kpis_helpers",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpis_compute",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6211bf5-f607-4130-82c2-3ebdcda68fb4"
      },
      "source": [
        "if not safe_exists(WET_GJ) or not safe_exists(DRY_GJ):\n",
        "    raise FileNotFoundError('Wet/Dry polygons were not found after normalization.')\n",
        "\n",
        "wet = gpd.read_file(WET_GJ)\n",
        "dry = gpd.read_file(DRY_GJ)\n",
        "\n",
        "utm = auto_utm_crs(wet)\n",
        "wet_m = wet.to_crs(utm)\n",
        "dry_m = dry.to_crs(utm)\n",
        "wet_area_km2 = float(wet_m.area.sum() / 1e6)\n",
        "dry_area_km2 = float(dry_m.area.sum() / 1e6)\n",
        "delta_km2    = wet_area_km2 - dry_area_km2\n",
        "\n",
        "lines = None\n",
        "if safe_exists(locals().get('LINES_GJ')):\n",
        "    lines = gpd.read_file(LINES_GJ)\n",
        "elif safe_exists(locals().get('POINTS_GJ')):\n",
        "    pts = gpd.read_file(POINTS_GJ)\n",
        "    utm = auto_utm_crs(wet)\n",
        "    pts_utm = pts.to_crs(utm)\n",
        "    F = 5.0\n",
        "    geoms = []\n",
        "    rows = []\n",
        "    if {'dx_m','dy_m'}.issubset(pts.columns):\n",
        "        for idx, r in pts.iterrows():\n",
        "            dx = float(r.get('dx_m', np.nan))\n",
        "            dy = float(r.get('dy_m', np.nan))\n",
        "            if not (np.isfinite(dx) and np.isfinite(dy)):\n",
        "                continue\n",
        "            p = pts_utm.loc[idx].geometry\n",
        "            if (p is None) or (not isinstance(p, Point)):\n",
        "                continue\n",
        "            x, y = float(p.x), float(p.y)\n",
        "            x2 = x + F*dx\n",
        "            y2 = y + F*dy\n",
        "            geoms.append(LineString([(x, y), (x2, y2)]))\n",
        "            rows.append(idx)\n",
        "        if geoms:\n",
        "            keep_cols = [c for c in pts.columns if c in ('speed_m_per_year','dir_deg_math','error','dx_m','dy_m')]\n",
        "            data = pts.loc[rows, keep_cols].copy()\n",
        "            lines = gpd.GeoDataFrame(data, geometry=geoms, crs=utm)\n",
        "        else:\n",
        "            print('No valid vectors could be built from points (missing dx/dy?).')\n",
        "            lines = None\n",
        "    else:\n",
        "        print(\"Points file does not have 'dx_m'/'dy_m'. Vectors will be omitted.\")\n",
        "\n",
        "kpis = {}\n",
        "if (lines is not None) and (not lines.empty) and ('speed_m_per_year' in lines.columns):\n",
        "    sp = lines['speed_m_per_year'].astype(float).replace([np.inf,-np.inf], np.nan).dropna()\n",
        "    if len(sp) > 0:\n",
        "        kpis['speed_p50'] = float(sp.quantile(0.50))\n",
        "        kpis['speed_p90'] = float(sp.quantile(0.90))\n",
        "        if {'dx_m','dy_m'}.issubset(lines.columns):\n",
        "            dx = lines['dx_m'].astype(float); dy = lines['dy_m'].astype(float)\n",
        "            mean_dir = float(np.degrees(np.arctan2(dy.mean(), dx.mean())))\n",
        "        elif 'dir_deg_math' in lines.columns:\n",
        "            mean_dir = float(np.nanmean(lines['dir_deg_math'].astype(float)))\n",
        "        else:\n",
        "            mean_dir = np.nan\n",
        "        mean_bearing = (90 - mean_dir) % 360 if np.isfinite(mean_dir) else np.nan\n",
        "        kpis['mean_bearing_deg'] = float(mean_bearing) if np.isfinite(mean_bearing) else None\n",
        "\n",
        "kpis['wet_area_km2'] = wet_area_km2\n",
        "kpis['dry_area_km2'] = dry_area_km2\n",
        "kpis['delta_km2']    = delta_km2\n",
        "kpis['period']       = f\"{WET_DATE} → {DRY_DATE}\"\n",
        "\n",
        "with open(OUT_JSON, 'w') as f:\n",
        "    json.dump(kpis, f, indent=2)\n",
        "\n",
        "print('KPIs:\\n', json.dumps(kpis, indent=2))\n",
        "\n",
        "center_lat, center_lon = get_center_latlon(wet)\n"
      ],
      "id": "kpis_compute",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KPIs:\n",
            " {\n",
            "  \"speed_p50\": 0.0,\n",
            "  \"speed_p90\": 29.64876572745471,\n",
            "  \"mean_bearing_deg\": 136.89338584574628,\n",
            "  \"wet_area_km2\": 623.3762887369749,\n",
            "  \"dry_area_km2\": 453.91479669836997,\n",
            "  \"delta_km2\": 169.4614920386049,\n",
            "  \"period\": \"2024-05-15 \\u2192 2024-09-15\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "folium_map",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1c19ec4f-d30c-444d-a092-98725e886a84"
      },
      "source": [
        "import folium\n",
        "from folium.features import GeoJsonTooltip\n",
        "from folium.plugins import Fullscreen, MiniMap, MeasureControl, MousePosition\n",
        "import numpy as np, os, json\n",
        "\n",
        "BINS = [20, 40, 80, 120]\n",
        "COLS = ['#a6cee3', '#1f78b4', '#33a02c', '#fb9a99', '#e31a1c']\n",
        "FAST_TH = 20\n",
        "SIMPLIFY_LINES = True\n",
        "SIMPL_TOL_M = 5.0\n",
        "\n",
        "def color_by_speed(v, qs=BINS, cols=COLS):\n",
        "    try:\n",
        "        v = float(v)\n",
        "    except:\n",
        "        return cols[0]\n",
        "    for q, c in zip(qs, cols):\n",
        "        if v <= q:\n",
        "            return c\n",
        "    return cols[-1]\n",
        "\n",
        "def auto_utm_crs(gdf):\n",
        "    g = gdf.to_crs(4326).geometry\n",
        "    c = (g.union_all() if hasattr(g, 'union_all') else g.unary_union).centroid\n",
        "    lon, lat = float(c.x), float(c.y)\n",
        "    zone = int((lon + 180)//6) + 1\n",
        "    south = '+south' if lat < 0 else ''\n",
        "    return f'+proj=utm +zone={zone} {south} +datum=WGS84 +units=m +no_defs'\n",
        "\n",
        "def bearing_to_compass(b):\n",
        "    dirs = ['N','NNE','NE','ENE','E','ESE','SE','SSE',\n",
        "            'S','SSW','SW','WSW','W','WNW','NW','NNW']\n",
        "    try:\n",
        "        return dirs[int((float(b) % 360)/22.5 + 0.5) % 16]\n",
        "    except:\n",
        "        return '–'\n",
        "\n",
        "wet_ll = wet.to_crs(4326)\n",
        "dry_ll = dry.to_crs(4326)\n",
        "\n",
        "m = folium.Map(location=[center_lat, center_lon], zoom_start=11, tiles='cartodbpositron')\n",
        "folium.TileLayer(\n",
        "    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
        "    name='ESRI World Imagery',\n",
        "    attr='Esri'\n",
        ").add_to(m)\n",
        "\n",
        "folium.GeoJson(\n",
        "    wet_ll, name='Lagoons — Wet season',\n",
        "    style_function=lambda f: {\n",
        "        'color': '#1f78b4', 'weight': 1, 'fillColor': '#1f78b4', 'fillOpacity': 0.15\n",
        "    }\n",
        ").add_to(m)\n",
        "\n",
        "folium.GeoJson(\n",
        "    dry_ll, name='Lagoons — Dry season',\n",
        "    style_function=lambda f: {\n",
        "        'color': '#ffbf00', 'weight': 1, 'fillColor': '#ffbf00', 'fillOpacity': 0.25\n",
        "    }\n",
        ").add_to(m)\n",
        "\n",
        "if (locals().get('lines') is not None) and (not lines.empty):\n",
        "    L = lines.dropna(subset=['geometry']).copy()\n",
        "    if SIMPLIFY_LINES and not L.empty:\n",
        "        try:\n",
        "            utm = auto_utm_crs(wet)\n",
        "            L = L.to_crs(utm).copy()\n",
        "            L['geometry'] = L.geometry.simplify(SIMPL_TOL_M, preserve_topology=True)\n",
        "            L = L[~L.geometry.is_empty & L.geometry.notna()].copy()\n",
        "            L = L.to_crs(4326)\n",
        "        except Exception:\n",
        "            L = L.to_crs(4326)\n",
        "    else:\n",
        "        L = L.to_crs(4326)\n",
        "\n",
        "    cols_avail = list(getattr(L, 'columns', []))\n",
        "    tooltip_fields = [c for c in ('speed_m_per_year','dir_deg_math','error') if c in cols_avail]\n",
        "\n",
        "    def style_fun(feat):\n",
        "        v = feat['properties'].get('speed_m_per_year', None)\n",
        "        return {'color': color_by_speed(v), 'weight': 2, 'opacity': 0.9}\n",
        "\n",
        "    folium.GeoJson(\n",
        "        L, name='Offset vectors', style_function=style_fun,\n",
        "        tooltip=GeoJsonTooltip(fields=tooltip_fields,\n",
        "                               aliases=['speed (m/yr)','dir (deg)','error'][:len(tooltip_fields)])\n",
        "    ).add_to(m)\n",
        "\n",
        "    if 'speed_m_per_year' in cols_avail:\n",
        "        try:\n",
        "            Lfast = L[L['speed_m_per_year'].astype(float) > FAST_TH]\n",
        "        except Exception:\n",
        "            Lfast = L.iloc[0:0]\n",
        "        if not Lfast.empty:\n",
        "            folium.GeoJson(\n",
        "                Lfast, name=f'Vectors (> {FAST_TH} m/yr)',\n",
        "                style_function=lambda f: {'color':'#e31a1c','weight':2,'opacity':0.9},\n",
        "                tooltip=GeoJsonTooltip(fields=tooltip_fields,\n",
        "                                       aliases=['speed (m/yr)','dir (deg)','error'][:len(tooltip_fields)])\n",
        "            ).add_to(m)\n",
        "\n",
        "Fullscreen().add_to(m)\n",
        "MiniMap(toggle_display=True).add_to(m)\n",
        "m.add_child(MeasureControl(\n",
        "    position='bottomleft',\n",
        "    primary_length_unit='kilometers',\n",
        "    secondary_length_unit='meters',\n",
        "    primary_area_unit='sqkilometers',\n",
        "    secondary_area_unit='hectares',\n",
        "    active_color='#e67e22',\n",
        "    completed_color='#2c3e50'\n",
        "))\n",
        "MousePosition(prefix='lat/lon').add_to(m)\n",
        "folium.LayerControl(collapsed=False, position='bottomleft').add_to(m)\n",
        "\n",
        "BASE_CARD_CSS = \"background:white;padding:12px 14px;border:1px solid #bbb;font-size:14px;line-height:1.35;\"\n",
        "TITLE_CSS = \"font-weight:600;font-size:14px;\"\n",
        "\n",
        "bins_labels = [f'≤{q:.0f}' for q in BINS] + ['>']\n",
        "legend_html = f'<div style=\"{BASE_CARD_CSS}\">'\n",
        "legend_html += f'<div style=\"{TITLE_CSS}\">Dune migration speed (m/yr)</div>'\n",
        "for label, c in zip(bins_labels, COLS + [COLS[-1]]):\n",
        "    legend_html += f'<div><i style=\"background:{c};width:12px;height:12px;display:inline-block;margin-right:8px;border:1px solid #888;\"></i>{label}</div>'\n",
        "legend_html += '</div>'\n",
        "\n",
        "k = {}\n",
        "try:\n",
        "    with open(OUT_JSON, 'r') as f:\n",
        "        k = json.load(f)\n",
        "except Exception:\n",
        "    k = {}\n",
        "\n",
        "def bearing_to_compass(b):\n",
        "    dirs = ['N','NNE','NE','ENE','E','ESE','SE','SSE','S','SSW','SW','WSW','W','WNW','NW','NNW']\n",
        "    try:\n",
        "        return dirs[int((float(b) % 360)/22.5 + 0.5) % 16]\n",
        "    except:\n",
        "        return '–'\n",
        "\n",
        "bearing = k.get('mean_bearing_deg', None)\n",
        "bearing_str = bearing_to_compass(bearing) if bearing is not None else '–'\n",
        "\n",
        "card_html = f\"\"\"\n",
        "    <div style=\"{BASE_CARD_CSS}\">\n",
        "      <div style=\"{TITLE_CSS}\">Arapuá Labs — Results (SAR / AOT)</div>\n",
        "      <div>Period: {k.get('period','–')}</div>\n",
        "      <hr style=\\\"margin: 6px 0; border-top: 1px solid #ddd;\\\">\n",
        "      <div style=\\\"{TITLE_CSS}; color:#1f78b4;\\\">Hydrology (Lagoon)</div>\n",
        "      <div>Lagoon area — wet season: {k.get('wet_area_km2',0):,.1f} km²</div>\n",
        "      <div>Lagoon area — dry season: {k.get('dry_area_km2',0):,.1f} km²</div>\n",
        "      <div style=\\\"font-weight:600;\\\">Δ Lagoon Area: {k.get('delta_km2',0):+,.1f} km²</div>\n",
        "      <hr style=\\\"margin: 6px 0; border-top: 1px solid #ddd;\\\">\n",
        "      <div style=\\\"{TITLE_CSS}; color:#e31a1c;\\\">Aeolian (Dune Migration)</div>\n",
        "      <div>Migration Speed (90% of Active Dunes): <span style=\\\"font-weight:600;\\\">{k.get('speed_p90',0):,.0f} m/yr</span></div>\n",
        "      <div>Overall Motion Speed (Median): {k.get('speed_p50',0):,.0f} m/yr</div>\n",
        "      <div>Mean Migration Direction: <span style=\\\"font-weight:600;\\\">{bearing_str}</span></div>\n",
        "    </div>\"\"\"\n",
        "\n",
        "ui_stack = f\"\"\"\n",
        "<div style=\\\"position: fixed; top: 20px; right: 20px; z-index: 9999; display: flex; gap: 14px;\\\">\n",
        "  {card_html if card_html else ''}\n",
        "  {legend_html}\n",
        "</div>\n",
        "\"\"\"\n",
        "m.get_root().html.add_child(folium.Element(ui_stack))\n",
        "\n",
        "m.save(OUT_HTML)\n",
        "OUT_HTML"
      ],
      "id": "folium_map",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/ArapuaLabs_GEE_Exports/map_results.html'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iframe_preview",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "outputId": "16c56f44-8901-4df5-a78e-d8f54731ae76"
      },
      "source": [
        "from IPython.display import IFrame\n",
        "IFrame(OUT_HTML, width=1100, height=650)"
      ],
      "id": "iframe_preview",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7e9a6fcce8d0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1100\"\n",
              "            height=\"650\"\n",
              "            src=\"/content/drive/MyDrive/ArapuaLabs_GEE_Exports/map_results.html\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}